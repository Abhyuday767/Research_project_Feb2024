# -*- coding: utf-8 -*-
"""Recurrence_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SAigw_sBCfPO7m3ERI8KcKtJhYxNaW7R
"""

!pip install scikit-learn

import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder    #for converting to numerical data
from sklearn.decomposition import PCA             #for dimensionality reduction
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

from google.colab import files
upload = files.upload()   #upload the file "Patient and Treatment Characteristics - Marked by Dr Anjali.xlsx" from your local storage

file_path = "Patient and Treatment Characteristics.xls"
df = pd.read_excel(file_path)

df

df.isnull().mean()  #notice how DOB has mean =1 which means it has all none values

columns_before_drop = df.columns


threshold = 0.8  #setting threshold as if 80% are missing values then drop column
columns_to_drop = df.columns[df.isnull().mean()>threshold]
df = df.drop(columns=columns_to_drop)


columns_after_drop = df.columns

dropped_columns = set(columns_before_drop)-set(columns_after_drop)     #DOB, Date Feeding tube placed, Date Feeding tube removed and Recurrence imaging date removed from the list of columns (as discussed with professor)
print("Dropped columns :")
for column in dropped_columns:
  print(column)

for column in df.columns:
    if df[column].dtype == 'int64' or df[column].dtype == 'float64':
      df[column] = df[column].fillna(df[column].mean())         #fill the missing values of numerical data type with MEAN
    elif df[column].dtype == 'object':
      df[column] = df[column].fillna(df[column].mode()[0])      #fill the missing values of categorical data type with MODE

df.columns[df.isnull().any()]        #as we can see, null values in only datetime[ns] data type are left, we will tackle them by analysing them manually

df['Date of Death'].isnull().sum()

df['Date of recurrence'].isnull().sum()

df['Pre-RT Imaging Date'].isnull().sum()

df['CT sim date'].isnull().sum()

df.drop('Date of Death', axis=1)   #as the no. of null values is 127 and we also have column survival(months)
for column in df.columns[df.isnull().any()]:          #replacing the other values with their respective MEAN
  mean_datetime = df[column].mean()
  df[column] = df[column].fillna(mean_datetime)

"""Converting to numerical form now.."""

df.select_dtypes(include=['int']).columns

df.select_dtypes(include=['object']).columns

df.select_dtypes(include=['datetime']).columns

label_encoder = LabelEncoder()

# Iterate through each column in the DataFrame
for col in df.columns:
    # Check if the column is categorical
    if df[col].dtype == 'object':
        # Fit label encoder and transform values
        df[col] = label_encoder.fit_transform(df[col].astype(str))
    elif df[col].dtype == 'datetime64[ns]':
        # Convert datetime columns to Unix timestamp
        df[col] = pd.to_datetime(df[col]).astype(int) / 10**9

df

#saving the converted numerical dataframe in an excel file as requested by the professor
df.to_excel("numerical_converted.xlsx", index=False)

print(f"DataFrame has been successfully exported")

# Instantiate PCA with 2 for visualization
pca = PCA(n_components=2)

# Fit PCA to your data
pca.fit(df)

# Transform the data using the fitted PCA
df_pca = pca.transform(df)

# Visualize the data in reduced dimensions (for 2D)
plt.scatter(df_pca[:, 0], df_pca[:, 1])
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA plot of the dataset')
plt.show()

print("present" if "Survival  (months)"in df.columns else "not present")

# Separate features and target variable
X = df.drop(columns=['Survival  (months)'])  # Features
y = df['Survival  (months)']  # Target variable

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply PCA for dimensionality reduction
pca = PCA(n_components=2)  # Adjust the number of components as needed
X_pca = pca.fit_transform(X_scaled)

# Create a new DataFrame with reduced dimensions
df_pca = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])

# Concatenate the target variable with the reduced DataFrame if needed
df_pca['Survival  (months)'] = y

# Now df_pca contains your dataset with reduced dimensions
df_pca

df_pca

"""**Could be used for dimensionality reduction for all the 4 goals mentioned in the readme documnet**


# Goal 1: Survival Prediction
# Features: age, diagnosis, grade, stage
# Target variable: Survival (possible or not)

# Prepare data for survival prediction
X_survival = df[['Age', 'Diag', 'Grade', 'Stage']]
y_survival = df['Alive or Dead']  # Assuming 'Alive or Dead' is the target variable

# Split the dataset into training and testing sets
X_train_survival, X_test_survival, y_train_survival, y_test_survival = train_test_split(X_survival, y_survival, test_size=0.2, random_state=42)

# Standardize the features
scaler_survival = StandardScaler()
X_train_survival_scaled = scaler_survival.fit_transform(X_train_survival)
X_test_survival_scaled = scaler_survival.transform(X_test_survival)

# Apply dimensionality reduction using PCA
pca_survival = PCA(n_components=0.95)
X_train_survival_pca = pca_survival.fit_transform(X_train_survival_scaled)
X_test_survival_pca = pca_survival.transform(X_test_survival_scaled)

# Train a classifier (e.g., Random Forest) for survival prediction
clf_survival = RandomForestClassifier(random_state=42)
clf_survival.fit(X_train_survival_pca, y_train_survival)

# Evaluate the classifier
y_pred_survival = clf_survival.predict(X_test_survival_pca)
accuracy_survival = accuracy_score(y_test_survival, y_pred_survival)
print("Accuracy for survival prediction:", accuracy_survival)

# Goal 2: Recurrence Analysis
# Features: age, stage
# Target variable: Recurrence (binary)

# Prepare data for recurrence analysis
X_recurrence = df[['Age', 'Stage']]
y_recurrence = df['Site of recurrence (Distal/Local/ Locoregional)']  # Assuming this represents recurrence

# Perform similar steps as above for preprocessing and modeling

# Goal 3: Chemotherapy Requirement
# Features: stage, sex, diagnosis
# Target variable: Chemotherapy requirement (binary)

# Prepare data for chemotherapy requirement analysis
X_chemo = df[['Stage', 'Sex', 'Diag']]
y_chemo = df['Chemotherapy Regimen']  # Assuming this represents chemotherapy requirement

# Perform similar steps as above for preprocessing and modeling

# Goal 4: Prescribed Dose Analysis
# Features: age, RT Total Dose (Gy), Dose/Fraction (Gy/fx)
# Target variable: None (unsupervised analysis)

# Prepare data for prescribed dose analysis
X_dose = df[['Age', 'RT Total Dose (Gy)', 'Dose/Fraction (Gy/fx)']]

# Perform unsupervised analysis (e.g., clustering) or other exploratory analysis on X_dose

"""



